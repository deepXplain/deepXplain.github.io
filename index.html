<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DeepXplain 2025</title>
  <!-- Adicionar Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
</head>
<body class="sticky-bottom-footer">

 <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Navbar Centered</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    .navbar-nav {
      display: flex;
      justify-content: center;
      width: 100%;
    }
  </style>
</head>
<body>
  <!-- Header -->
  <header>
    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top bg-light">
      <div class="container">
        <!-- Navbar Brand -->
        <a class="navbar-brand" href="#"></a>

        <!-- Navbar Toggle -->
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <!-- Navbar Links -->
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav mx-auto">
            <li class="nav-item active">
              <a class="nav-link" href="#about">Home <span class="sr-only">(current)</span></a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#program">Program</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#cfp">Call For Papers</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#dates">Important Dates</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#organization">Organization</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#proceedings">Proceedings</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#venue">Venue</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>
  </header>

  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.2/dist/js/bootstrap.bundle.min.js"></script>



  <!-- Adicionar Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.4/dist/umd/popper.min.js"></script>
 <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>

<!-- Adicione o seguinte CSS no seu arquivo de estilos -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction</title>
    <style>
        body {
            margin: 100px; /* Define a margem de todo o corpo da página */
            font-family: Arial, sans-serif;
            line-height: 1.6;
        }
        h4 {
            margin-bottom: 10px; /* Espaço abaixo do título */
        }
        p {
            margin-left:  80px; /* Define margem apenas à esquerda */
            margin-right: 80px; /* Define margem apenas à direita */
            text-align: justify; /* Justifica o texto */
        }
        a {
            color: blue;
            text-decoration: underline;
        }
    </style>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Change Color</title>
    <style>
        body {
            margin: 20px;
            font-family: Arial, sans-serif;
        }
        h4 {
          color: #800000;
          }
    </style>
</head>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Centered Header</title>
  <style>
    h6 {
      text-align: center; /* Centraliza o texto dentro do h4 */
    }
  </style>
</head>
  <style>
    ul {
        margin: 40px;
    }
</style>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Announcement</title>
    <style>
        .announcement {
            text-align: left;
            color: #800000;
        }
  
    </style>
</head>


 
<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="img/logo-deepxplain.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta charset="utf-8">
    <meta name="description" content="IJCNN 2025 Special Session on Explainable Deep Neural Networks for Responsible AI: Post-Hoc and Self-Explaining Approaches (DeepXplain 2025)">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Deep Learning, Responsible AI, Interpretability and Explainability, Artificial Intelligence">
    <!-- <meta name="google-site-verification" content="PmOT4QwF1x9TSSKYFg6if9CR_TojuEk8pFDffRgdfns"> -->
    <meta name="twitter:card" content="summary_large_image">
    <meta property="og:title" content="IJCNN 2025 Special Session on Explainable Deep Neural Networks for Responsible AI: Post-Hoc and Self-Explaining Approaches (DeepXplain 2025)">
    <meta property="og:description" content="In this Special Session, we invite the research community in quantum information science and machine learning to submit works related to the integration of quantum computing with machine learning.">
    
  
    <title>IJCNN 2025 Special Session on Explainable Deep Neural Networks for Responsible AI: Post-Hoc and Self-Explaining Approaches (DeepXplain 2025)</title> 
</head>

<body>

    <div class="banner" style="text-align: center;">
        <img src="img/deepxplain-logo.png" alt="Special Session Banner" style="width: 50%">
        <!-- <div class="top-center"> -->
        <!--    <span class="title1">IJCNN Special Session on </span> <br> -->
        <!--    <span class="title2">Explainable Deep Neural Networks for Responsible AI</span> <br> -->
        <!--    <span class="title2">Post-Hoc and Self-Explaining Approaches </span> <br> -->
        <!--    <span class="title3">(DeepXplain 2025)</span> <br> -->
        <!--    <span class="year">2025</span> <br> -->
</div>
    
    <h6>Co-located with <a target="_blank", text-align: center, href="https://2025.ijcnn.org/">International Joint Conference on Neural Networks (IJCNN 2025)</a> Roma, Italy</h6>

<hr> </hr>  
    <h4>Introduction</h4>
  <font size="3">
    <p> The adoption of Deep Neural Networks (DNNs)—e.g., CNNs, GANs, RNNs, LSTMs, and LLMs — in critical domains such as healthcare, governance, misinformation, 
      and hate speech detection has created an unprecedented demand for high-performance and interpretable models. Despite their success, the opaque nature of DNNs 
      undermines user trust and raises ethical concerns, especially in sensitive applications. The need for Explainable Artificial Intelligence (XAI) methods has 
      never been more pressing, and both post-hoc and self-explaining approaches hold promise in addressing this challenge. <b>The IJCNN 2025 Special Session on
      Explainable Deep Neural Networks for Responsible AI: Post-Hoc and Self-Explaining Approaches (DeepXplain 2025)</b> aims to bring together researchers in 
      Natural Language Processing (NLP), Computer Vision (CV), Machine Learning (ML), Explainable IA (XAI), Ethics, and practitioners. This session aims to explore 
      innovative methodologies that enhance the interpretability of Deep Neural Networks (DNNs), address fairness and bias mitigation, and maintain predictive accuracy.
     </p>
    <p>  <b>Specific areas of focus include:</b> (i) post-hoc techniques (e.g., SHAP, LIME, Grad-CAM), (ii) self-explaining neural network architectures (e.g., feature saliency, attention mechanisms, 
      prototype networks, and SENNs [Self-Explaining Neural Networks]), and (iii) discussions, methods, or interdisciplinary evaluations of DNN-based AI systems that use interpretability to address fairness, trust, and social impact.
    </p>
  </font>
  
<hr> </hr> 
    <h4 id="cfp">Call For Papers</h4>
  
  <h5>Topics</h5>
  <font size="3">
    <p>In this special session, we aim to foster interdisciplinary collaboration, promote the ethical design of DNN-based AI systems, and encourage the development of benchmarks and datasets 
      for explainability and fairness research. Our goal is to advance both post-hoc and intrinsic interpretability approaches, bridging the gap between the high performance of deep neural networks 
      and their transparency. By doing so, we seek to enhance human trust in these models and mitigate the risks of negative social impacts. Topics of interest include, but are not limited to:
    </p>
        <ul>
            <li>Theoretical and practical advances in post-hoc explanation methods (LIME, SHAP, Grad-CAM) for DNNs.  </li>
            <li>Development of inherently interpretable architectures utilizing self-explaining mechanisms, such as attention-based models, prototype networks, and SENNs.</li>
            <li>Post-hoc and self-explaining methods for transformer-based architectures (e.g., BERT, GPT, T5, etc.).</li>
            <li>Post-hoc and self-Explaining methods focused on Large Language Models (LLMs).</li>
            <li>Studies on the evaluation of explainable methods to address bias in DNN-based models.</li>
            <li>Counterfactual explainable approaches in DNNs.</li>
            <li>Application-driven insights, particularly in Natural Language Processing and Computer Vision.</li>
            <li>Ethical evaluations of DNN-based models using explainability to mitigate bias and negative societal impact.</li>
            <li>Methods, metrics, and methodologies for improving interpretability and fairness in DNNs.</li>
            <li>Benchmark datasets and methods for explainability and interpretability in DNNs.</li>
            <li>Explainable AI in critical applications: healthcare, governance, misinformation, hate speech detection, etc.</li>
            <li>Metrics and methodologies for evaluating interpretability and fairness in DNNs.</li>
        </ul>
    <p>The list above is by no means exhaustive, as the aim is to foster the debate around all aspects of the suggested integration.</p>
  </font>
  
<hr> </hr>
    <h4>Submission</h4>
    <h5>Guidelines</h5>
 <font size="3">
    <p>Papers should be formatted according to the <a target="_blank" href="https://2025.ijcnn.org/authors/initial-author-instructions">IJCNN-2025 formatting guidelines</a> and 
        submitted as a single PDF file. We welcome submissions across the full spectrum of theoretical and practical work 
        including research ideas, methods, tools, simulations, applications or demos, practical evaluations, and position papers and surveys. 
        All papers will be peer-reviewed in a <em>double-blind</em> process and assessed based on their novelty, technical quality, potential 
        impact, clarity, and reproducibility (when applicable). Special Session submissions will be handled by EDAS; <strong>the submission link is as follows</strong>: 
        <a href="https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FConference%2FRecent" target="_blank">https://edas.info/N31614</a> Please select the respective special session title 
        "<strong>Explainable Deep Neural Networks for Responsible AI: Post-Hoc and Self-Explaining Approaches (DeepXplain 2025)</strong>" under the list of research topics 
        in the submission system.</p>
  </font>
<hr> </hr> 
    <h4 id="dates">Important Dates</h4>
   <font size="3">
    <ul>
    <div class="announcement">
      <li><b>Jan 30, 2025</b>: New Paper Submission Due Date (<a href="https://cmt3.research.microsoft.com/IJCNN2025/" target="_blank">Submission link</a>)</li>
      <li><b>Mar 31, 2025</b>: Notification of Paper Acceptance</li>
      <li><b>May 1, 2025</b>: Camera-ready Papers Due</li>
    </div> 
    <li><b>June 30 - July 5</b>, 2025: Conference Date</li>
    </ul> 
    <p><em><u>Note</u></em>: All deadlines are AoE <a href="https://time.is/Anywhere_on_Earth" target="_blank">(Anywhere on Earth)</a>.</p>
  </font>
<hr> </hr> 
    <h4 id="proceedings">Proceedings</h4>
 <font size="3">
    <p>The accepted papers will appear on the Special Session website and are included in the IJCNN conference proceedings.</p>
 </font>
  
<hr> </hr> 
    <h4 id="program">Special Session Program</h4>

   <p><b>Accepted Papers</b></p>
     <font size="3">  
   <ul>
        <li><strong>AttentionDefense: Leveraging System Prompt Attention for Explainable Defense Against Novel Jailbreaks</strong>, Charlotte Siska and Anush Sankaran</li>
        <li><strong>Intersectional Bias Quantification in Facial Image Processing with Pre-Trained ImageNet Classifiers</strong>, Valerie Krug, Florian Röhrbein and Sebastian Stober 
        <li><strong>Segmentation and Smoothing Affect Explanation Quality More Than the Choice of Perturbation-based XAI Method for Image Explanations</strong>, Gustav Grund Pihlgren, Kary Främling</li>
        <li><strong>DLBacktrace: Model Agnostic Explainability for any Deep Learning Model</strong>, Vinay Kumar Sankarapu, Chintan Chitroda, Pratinav Seth and Neeraj Singh</li> 
        <li><strong>Muppet: a modular and constructive decomposition for perturbation-based explanation methods</strong>, Quentin Ferré, Ismail Bachchar, Hakima Arroubat, Aziz Jedidi, Youssef Achenchabe and Antoine Bonnefoy</li>
        <li><strong>How can we trust opaque systems? Three criteria for robust explanations in XAI</strong>, Annika Schuster and Florian J. Boge</li>      
    </ul> 
  </font>
  
<hr> </hr> 
    <h4 id="organization">Organization</h4>
  
  <h5>Organizing Committee</h5>
   <font size="3">  
   <ul>
        <li><strong><a href="https://franciellevargas.github.io/">Francielle Vargas</a></strong>, University of São Paulo, Brazil</li>
        <li><strong><a href="https://sites.icmc.usp.br/rafrance/">Roseli Romero</a></strong>, University of São Paulo, Brazil</li>
        <li><strong><a href="https://www.jacksonptrager.com/">Jackson Trager</a></strong>, University of Southern California, USA</li>
        
    </ul> 
  </font>
  
  <h5>Program Committee</h5>
  <font size="3">  
   <ul>
        <li><strong><a href="https://exascale.info/members/alisa-smirnova/">Alisa Smirnova</a></strong>, Université de Fribourg, Switzerland</li>
        <li><strong><a href="https://www.linkedin.com/in/ajayvallabkrishnanprabhakaran/">Ajay Vallab</a></strong>, Meta, USA</li>
        <li><strong><a href="https://www.linkedin.com/in/ajayvallabkrishnanprabhakaran/">Aline Paes</a></strong>, Federal Fluminense University, Brazil</li>
        <li><strong><a href="https://www.pnnl.gov/people/ellyn-ayton">Ellyn Ayton</a></strong>, Portland State University, USA</li>
        <li><strong><a href="https://www.inf.ufrgs.br/~prestes/site/Welcome.html">Edison Prestes</a></strong>, Federal University of Rio Grande do Sul, Brazil</li>
        <li><strong><a href="https://scholar.google.com/citations?user=agANVQoAAAAJ&hl=en"> Jinwei Xing </a></strong>, Google, USA</li>
        <li><strong><a href="https://scholar.google.com/citations?user=xcu5uosAAAAJ"> Ellyn Ayton </a></strong>, Pacific Northwest National Laboratory, USA</li>
        <li><strong><a href="https://www.researchgate.net/profile/Maira-Lira-2"> Maira Lira </a></strong>, Federal University of Pernambuco, Brazil</li>
        <li><strong><a href="https://scholar.google.com/citations?user=SUU9998AAAAJ">  Marco Huber </a></strong>, University of Stuttgart, Germany</li>
        <li><strong><a href="https://scholar.google.com/citations?user=hHqaacIAAAAJ"> Liyuan Gao</a></strong>, Texas Tech University, USA</li>
        <li><strong><a href="https://www.linkedin.com/in/lenayingli/">Ying Li</a></strong>, Meta, USA</li>
        <li><strong><a href="https://www.fmorenovr.com/">Felipe Moreno</a></strong>, FGV, Brazil</li>
        <li><strong><a href="https://www.ime.usp.br/~mfinger/">Marcelo Finger</a></strong>, University of São Paulo, Brazil</li>
        <li><strong><a href="https://scholar.google.com/citations?user=TuoyWi8AAAAJ&hl=ko">Bum Jun Kim</a></strong>, University of Tokyo, Japan</li>
        <li><strong><a href="http://www.llf.cnrs.fr/fr/Gens/Martin">Philippe Martin</a></strong>, Université Paris Diderot, France</li>
        <li><strong><a href="https://www.cs.montana.edu/sheppard/">John W. Sheppard</a></strong>, Montana State University, USA</li>
        <li><strong><a href="https://sinaai.github.io/">Sina Bagheri Nezhad</a></strong>, Portland State University, USA</li>
        <li><strong><a href="https://www.linkedin.com/in/sudharshan-reddy-tumkunta-3980451b/">Sudharshan Tumkunta</a></strong>, Meta, USA</li> 
        <li><strong><a href="https://scholar.google.com/citations?user=2GH5rWkAAAAJ"> Xiuwen Liu</a></strong>, Florida State University, USA</li>  
    </ul> 
  </font>
    
<hr></hr> 
    <h4 id="venue">Venue</h4>
    
    <p><a href="https://2025.ijcnn.org/travel/venue">How to Reach the Venue</a></p>

    <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d1624.9213482198165!2d139.63484198878092!3d35.45868859316495!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x60185d91f264e855%3A0x90ab898535a197b3!2sPacifico%20Yokohama%20Conference%20Center!5e0!3m2!1sen!2sus!4v1701994394848!5m2!1sen!2sus" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
    <p><a href="#top">Go back to the top</a></p>

    <footer>
        &copy; Workshop Organizers
        &nbsp;|&nbsp; Design by <a target="_blank" href="https://github.com/mikepierce">Francielle Vargas</a>
        &nbsp;|&nbsp; Sponsored by <a target="_blank" href="https://2025.ijcnn.org/">IJCNN-2025</a>
    </footer>

</body>
</html>
